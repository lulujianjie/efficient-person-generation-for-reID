{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import shutil\n",
    "\n",
    "from config.config import Configuration\n",
    "Cfg = Configuration()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = Cfg.DEVICE_ID\n",
    "\n",
    "preds = np.load('./log/preds.npy')\n",
    "cids = np.load('./log/cids.npy')\n",
    "h1ids = np.load('./log/h1ids.npy')\n",
    "print(h1ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_at_hop = Cfg.NUM_HOP\n",
    "knn = np.load('./log/knn.npy')\n",
    "knn_graph = knn[:, :k_at_hop[0] + 1]\n",
    "print(knn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_graph = {}\n",
    "for idx in range(knn_graph.shape[0]):\n",
    "    hops = list()\n",
    "    center_node = idx\n",
    "    depth = len(k_at_hop)\n",
    "    hops.append(set(knn_graph[center_node][1:]))\n",
    "\n",
    "    # Actually we dont need the loop since the depth is fixed here,\n",
    "    # But we still remain the code for further revision\n",
    "    for d in range(1, depth):\n",
    "        hops.append(set())\n",
    "        for h in hops[-2]:\n",
    "            hops[-1].update(set(knn_graph[h][1:k_at_hop[d] + 1]))\n",
    "\n",
    "    hops_set = set([h for hop in hops for h in hop])\n",
    "    hops_set.update([center_node, ])\n",
    "    unique_nodes_list = list(hops_set)\n",
    "    # node_list including pivot, 1-hop, and 2-hop nodes\n",
    "    unique_nodes_map = {j: i for i, j in enumerate(unique_nodes_list)}\n",
    "    tmp_ = []\n",
    "    for i, pred_edge in enumerate(preds[idx]):\n",
    "        score = np.exp(pred_edge[1])/np.exp(pred_edge).sum()\n",
    "        #print(score)\n",
    "        #if np.argmax(pred_edge) == 1:\n",
    "        if score > 0.5:\n",
    "            #print(unique_nodes_map.keys())\n",
    "            tmp_.append(list(unique_nodes_map.keys())[list(unique_nodes_map.values()).index(h1ids[idx][0][i])])\n",
    "    print('=>Processing {}'.format(idx+1))\n",
    "    pred_graph[idx] = tmp_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH_NPY = '/nfs-data/lujj/projects/tmp_extraction_features/log/img_path.npy'\n",
    "img_paths = np.load(IMG_PATH_NPY)\n",
    "print(img_paths.shape)\n",
    "pseudo_labels = []\n",
    "for img_path in img_paths:\n",
    "    pseudo_labels.append(img_path.split('/')[-1].split('_')[0])\n",
    "np.save('./log/persudo_labels.npy', pseudo_labels)\n",
    "print(len(pseudo_labels))\n",
    "pseudo_labels_dict = {}\n",
    "for v,k in enumerate(pseudo_labels):\n",
    "    pseudo_labels_dict[k]=[]\n",
    "for v,k in enumerate(pseudo_labels):\n",
    "    pseudo_labels_dict[k].append(v)\n",
    "print(len(pseudo_labels_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(list1, list2):\n",
    "    union = []\n",
    "    inter = []\n",
    "    union.extend(list1)\n",
    "    union.extend(list2)\n",
    "    for item in list1:\n",
    "        if item in list2:\n",
    "            inter.append(item)\n",
    "    return len(inter)/(len(set(union))+0.0001)\n",
    "\n",
    "def AffinityClusterPreservation(unlabel_list, len_unlabel_list, tmp_i2idx):\n",
    "    preserved_indices = []\n",
    "    max_cluster_len = max(len_unlabel_list)\n",
    "    max_cluster = unlabel_list[np.argmax(len_unlabel_list)]\n",
    "    if max_cluster_len == 0:\n",
    "        return preserved_indices\n",
    "    else:\n",
    "        for i, cluster in enumerate(unlabel_list):\n",
    "            if IoU(max_cluster, cluster) >=0.1:\n",
    "                preserved_indices.extend(cluster)\n",
    "    return preserved_indices\n",
    "\n",
    "preserved_indices = []\n",
    "for pid in pseudo_labels_dict.keys():\n",
    "    print('=> Processing PID {}'.format(pid))\n",
    "    indices = pseudo_labels_dict[pid]\n",
    "    unlabel_list = []\n",
    "    len_unlabel_list = []\n",
    "    tmp_i2idx = {}\n",
    "    for tmp_i,idx in enumerate(indices):\n",
    "        tmp_i2idx[tmp_i] = idx\n",
    "        unlabel_list.append(pred_graph[idx])\n",
    "        len_unlabel_list.append(len(pred_graph[idx]))\n",
    "    print(len(AffinityClusterPreservation(unlabel_list, len_unlabel_list, tmp_i2idx)))\n",
    "    preserved_indices.extend(AffinityClusterPreservation(unlabel_list, len_unlabel_list, tmp_i2idx)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(preserved_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp\n",
    "_l = set()\n",
    "unused_img_list = []\n",
    "for idx in range(knn_graph.shape[0]):\n",
    "    for item in pred_graph[idx]:\n",
    "        if item not in _l:\n",
    "            _l.add(item)\n",
    "print('Retained #image:',len(_l))\n",
    "for item in range(h1ids.shape[0]):\n",
    "    if item not in _l:\n",
    "        unused_img_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH_NPY = '/nfs-data/lujj/projects/test-on-PKU_Vehicle/log/img_path.npy'\n",
    "img_paths = np.load(IMG_PATH_NPY)\n",
    "for i, img_path in enumerate(img_paths):\n",
    "    #if i not in unused_img_list:\n",
    "    if i in len(set(preserved_indices)):\n",
    "        src = img_path\n",
    "        camid = str(np.random.randint(1,7))\n",
    "        pid = str(img_path.split('/')[-1].split('_')[0])\n",
    "        target_img = '{}'.format(pid)+'_c{}s0_'.format(camid)+ ''.join(random.sample(string.ascii_letters + string.digits, 10))+'.jpg'\n",
    "        dst = '/home/lujj/datasets/Market-1501-v15.09.15/p2_g_gcn/'+target_img\n",
    "        shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Duke\n",
    "IMG_PATH_NPY = '/nfs-data/lujj/projects/tmp_extraction_features/log/img_path.npy'\n",
    "img_paths = np.load(IMG_PATH_NPY)\n",
    "for i, img_path in enumerate(img_paths):\n",
    "    #if i not in unused_img_list:\n",
    "    if i in set(preserved_indices):\n",
    "        src = img_path\n",
    "        camid = str(np.random.randint(1,7))\n",
    "        pid = str(img_path.split('/')[-1].split('_')[0])\n",
    "        target_img = '{}'.format(pid)+'_c{}_'.format(camid)+ ''.join(random.sample(string.ascii_letters + string.digits, 10))+'.jpg'\n",
    "        dst = '/home/lujj/datasets/DukeMTMC-reID/p3_g_gcn/'+target_img\n",
    "        shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '0020_c6_f0031012'\n",
    "target = '0085_c8_f0024220'\n",
    "img1_path = '/home/lujj/datasets/DukeMTMC-reID/bounding_box_train/{}.jpg'.format(source)\n",
    "pose2_path = '/home/lujj/datasets/DukeMTMC-reID/train_part_heatmap/{}.jpg.npy'.format(target)\n",
    "img1 = read_image(img1_path)\n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "img1 = torch.unsqueeze(test_transforms(img1),0).to(device)\n",
    "pose_heatmap2 = np.load(pose2_path).astype(np.float32)\n",
    "pose2 = torch.tensor(pose_heatmap2.transpose((2, 0, 1)))\n",
    "pose2 = torch.unsqueeze(pose2,0).to(device)\n",
    "input_G = (img1, pose2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
