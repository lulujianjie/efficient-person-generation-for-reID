{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from config.cfg import Cfg\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "from datasets.bases import read_image\n",
    "sys.path.append('.')\n",
    "from datasets import make_dataloader\n",
    "from processor import do_inference\n",
    "from model import make_model\n",
    "from utils.logger import setup_logger\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#rename img\n",
    "import string\n",
    "import random\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "WEIGHT_PATH = '/nfs-data/lujj/projects/tmp_pose_tranfer_2/log/model_G_1800.pth'\n",
    "#'/nfs-data/lujj/pretrained_model/pose-transfer/model_G_45.pth'\n",
    "#'/nfs-data/lujj/projects/pose-transfer-jack-reid-01/log/tmp/model_G_180.pth'\n",
    "Cfg.freeze()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"5\"\n",
    "cudnn.benchmark = True\n",
    "\n",
    "test_transforms = T.Compose([\n",
    "        T.Resize(Cfg.MODEL.INPUT_SIZE),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "model_G, _, _, _ = make_model(Cfg)\n",
    "model_G.to(device)\n",
    "#model_G = nn.DataParallel(model_G)\n",
    "model_G.load_state_dict(torch.load(WEIGHT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Market-1501-v15.09.15'\n",
    "root_dir = '/home/lujj/datasets/{}/'.format(dataset)\n",
    "data_dir = 'p4'\n",
    "target_dir = '/home/lujj/datasets/{}/{}_g/'.format(dataset,data_dir)\n",
    "target_dir2 = '/home/lujj/datasets/{}/{}_g_bak/'.format(dataset,data_dir)\n",
    "img_list = []\n",
    "pid_set = set()\n",
    "for img in os.listdir(root_dir+data_dir):\n",
    "    pid = img.split('_')[0]\n",
    "    if pid in pid_set:\n",
    "        continue\n",
    "    else:\n",
    "        pid_set.add(pid)\n",
    "for img in os.listdir('/home/lujj/datasets/{}/bounding_box_train/'.format(dataset)):\n",
    "    pid = img.split('_')[0]\n",
    "    if pid in pid_set:\n",
    "        continue\n",
    "    else:\n",
    "        pid_set.add(pid)\n",
    "        img_list.append(img)\n",
    "print('to generate pid:',len(img_list))\n",
    "pose_list = os.listdir('/home/lujj/datasets/Market-1501-v15.09.15/pose_list/')\n",
    "len_pose = len(pose_list)\n",
    "print('body-part:',len_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = 17\n",
    "model_G.eval()\n",
    "for img in img_list:\n",
    "    if img[-3:] == 'jpg':\n",
    "        img1_path = '/home/lujj/datasets/{}/bounding_box_train/{}'.format(dataset,img)\n",
    "        for pose2_idx in np.random.choice(range(len_pose),num_imgs, replace=False):\n",
    "            target_pose = pose_list[pose2_idx]\n",
    "            pose2_path = '/home/lujj/datasets/Market-1501-v15.09.15/train_part_heatmap/{}.npy'.format(target_pose)\n",
    "            img1 = read_image(img1_path)\n",
    "        # plt.imshow(img1)\n",
    "        # plt.show()\n",
    "            img1 = torch.unsqueeze(test_transforms(img1),0).to(device)\n",
    "            pose_heatmap2 = np.load(pose2_path).astype(np.float32)\n",
    "            pose2 = torch.tensor(pose_heatmap2.transpose((2, 0, 1)))\n",
    "            pose2 = torch.unsqueeze(pose2,0).to(device)\n",
    "            input_G = (img1, pose2)\n",
    "\n",
    "            fake_img2 = model_G(input_G)\n",
    "            result = fake_img2.cpu().detach().numpy()\n",
    "            img1 = (np.transpose(result[0],(1,2,0))+ 1) / 2.0 * 255.0\n",
    "            cv2.imwrite(target_dir+'{}-{}.jpg'.format(img[:-4],target_pose[:-4]),cv2.cvtColor(img1, cv2.COLOR_RGB2BGR))\n",
    "            cv2.imwrite(target_dir2+'{}-{}.jpg'.format(img[:-4],target_pose[:-4]),cv2.cvtColor(img1, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for img in os.listdir(target_dir):\n",
    "    src = target_dir+img\n",
    "    target_img = ''.join(random.sample(string.ascii_letters + string.digits, 10))+'.jpg'\n",
    "    img_ = img.split('-')\n",
    "    dst = target_dir+img_[0]+target_img\n",
    "    os.rename(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
